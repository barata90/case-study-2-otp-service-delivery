{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47bdf82",
   "metadata": {},
   "source": [
    "# Airline On\u2011Time Performance (OTP) Analytics\n",
    "\n",
    "**Theme:** Operational Performance & Service Delivery (OTP, delays, cancellations, diversions)\n",
    "\n",
    "**Primary data source (official):** U.S. DOT Bureau of Transportation Statistics (BTS) TranStats \u2014 *On\u2011Time: Reporting Carrier On\u2011Time Performance (1987\u2013present)*.\n",
    "\n",
    "**Portfolio focus**\n",
    "\n",
    "- KPI monitoring: OTP, delay minutes, cancellation & diversion rates\n",
    "- Anomaly detection: routes / airports with persistent (\u201cchronic\u201d) delay patterns and sudden spikes\n",
    "- Forecasting: short\u2011horizon delay risk from time series patterns\n",
    "- Root\u2011cause by delay type: carrier / weather / NAS / security / late aircraft\n",
    "\n",
    "**Notes on scale**\n",
    "\n",
    "BTS flight\u2011level OTP files can be very large (millions of rows). This notebook supports:\n",
    "\n",
    "- loading a subset of columns (recommended),\n",
    "- optionally limiting rows for a demo run,\n",
    "- generating a synthetic dataset when a local BTS extract is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2a8e0",
   "metadata": {},
   "source": [
    "## 1) Data acquisition (BTS TranStats)\n",
    "\n",
    "TranStats provides a configurable download page (filter by year/month and select columns). The dataset profile and the download UI are available from the official portal:\n",
    "\n",
    "- Database profile / description: https://transtats.bts.gov/DatabaseInfo.asp (search for \u201cReporting Carrier On\u2011Time Performance\u201d)\n",
    "- Download UI (field selection, year/month filters): https://www.transtats.bts.gov/DL_SelectFields.aspx (dataset: Reporting Carrier On\u2011Time Performance)\n",
    "- Field list / dictionary: https://transtats.bts.gov/Fields.asp\n",
    "- Airline on\u2011time statistics portal (aggregations): https://www.transtats.bts.gov/ontime/\n",
    "\n",
    "**Local file expectation**\n",
    "\n",
    "This notebook expects a locally saved extract (CSV/CSV.GZ/ZIP containing a CSV). A typical workflow:\n",
    "\n",
    "1. Download a month (or a small range) from TranStats using the filters.\n",
    "2. Select only the columns needed for analysis (reduces file size and load time).\n",
    "3. Save the file under `data/` and point `DATA_PATH` to it.\n",
    "\n",
    "A synthetic dataset is created automatically if `DATA_PATH` does not exist, enabling full execution without external files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefd1b1",
   "metadata": {},
   "source": [
    "## 2) Environment setup\n",
    "\n",
    "Recommended packages:\n",
    "\n",
    "- pandas, numpy\n",
    "- matplotlib\n",
    "- scikit\u2011learn\n",
    "- statsmodels\n",
    "\n",
    "Optional (nice\u2011to\u2011have): pyarrow (faster CSV), duckdb (SQL on large files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fe0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Forecasting\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "plt.rcParams['figure.dpi'] = 130"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5dda2",
   "metadata": {},
   "source": [
    "## 3) Load data\n",
    "\n",
    "- `DATA_PATH` may point to a `.csv`, `.csv.gz`, or `.zip` (ZIP containing a CSV).\n",
    "- `MAX_ROWS_FOR_DEMO` can cap the number of rows loaded (useful for quick runs).\n",
    "- If the file does not exist, a synthetic dataset is generated to keep the notebook runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc435fe",
   "metadata": {},
   "outputs": [],
   "source": "DATA_PATH = os.environ.get('BTS_OTP_PATH', 'data/On_Time_Reporting_Carrier.csv')\nMAX_ROWS_FOR_DEMO = int(os.environ.get('BTS_MAX_ROWS', '0'))  # 0 = load all rows\n\n# Column subset for common OTP/Delay analytics\nUSE_COLS = [\n    'FlightDate','Year','Month','DayOfWeek',\n    'Reporting_Airline','Flight_Number_Reporting_Airline',\n    'Origin','Dest','Distance',\n    'DepDelayMinutes','ArrDelayMinutes','DepDel15','ArrDel15',\n    'Cancelled','CancellationCode','Diverted',\n    'CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay'\n]\n\ndef read_bts_file(path: str, usecols=None, max_rows: int = 0) -> pd.DataFrame:\n    \"\"\"Read BTS extract from CSV/CSV.GZ/ZIP (ZIP contains a CSV).\"\"\"\n    nrows = None if max_rows == 0 else max_rows\n\n    if path.lower().endswith('.zip'):\n        with zipfile.ZipFile(path, 'r') as zf:\n            candidates = [n for n in zf.namelist() if n.lower().endswith('.csv')]\n            if not candidates:\n                raise ValueError('ZIP does not contain a CSV file.')\n            csv_name = candidates[0]\n            with zf.open(csv_name) as f:\n                return pd.read_csv(f, usecols=usecols, nrows=nrows, low_memory=False)\n\n    # pandas auto-detects gzip via extension when compression is not specified\n    return pd.read_csv(path, usecols=usecols, nrows=nrows, low_memory=False)\n\n\ndef make_synthetic_bts_like(n_rows: int = 60000, seed: int = 7) -> pd.DataFrame:\n    \"\"\"Create a BTS-like dataset (schema subset) for demonstration and reproducibility.\"\"\"\n    rng = np.random.default_rng(seed)\n\n    airlines = np.array(['AA','DL','UA','WN','B6','AS'])\n    airports = np.array(['ATL','DFW','DEN','ORD','LAX','JFK','SEA','MCO','PHX','CLT'])\n\n    # Dates across ~4 months\n    start = np.datetime64('2024-05-01')\n    days = rng.integers(0, 120, size=n_rows)\n    flight_dates = start + days.astype('timedelta64[D]')\n\n    origin = rng.choice(airports, size=n_rows)\n    dest = rng.choice(airports, size=n_rows)\n    # Avoid origin == dest\n    same = origin == dest\n    dest[same] = rng.choice(airports, size=same.sum())\n\n    reporting_airline = rng.choice(airlines, size=n_rows)\n    flight_no = rng.integers(1, 9999, size=n_rows)\n    distance = rng.integers(150, 2800, size=n_rows)\n\n    # Baseline delay structure with airport and route effects\n    airport_effect = {a: rng.normal(0, 3) for a in airports}\n    route_key = np.char.add(np.char.add(origin, '-'), dest)\n    unique_routes = np.unique(route_key)\n    route_effect = {r: rng.normal(0, 4) for r in unique_routes}\n\n    base_dep = rng.normal(6, 12, size=n_rows)\n    base_arr = base_dep + rng.normal(2, 10, size=n_rows)\n\n    dep = base_dep + np.vectorize(airport_effect.get)(origin)\n    arr = base_arr + np.vectorize(route_effect.get)(route_key)\n\n    # Introduce a few spike events for anomaly detection\n    spike_days = np.array(['2024-06-15', '2024-07-04', '2024-07-25'], dtype='datetime64[D]')\n    spike_mask = np.isin(flight_dates.astype('datetime64[D]'), spike_days) & (origin == 'ORD')\n    arr[spike_mask] += rng.normal(35, 12, size=spike_mask.sum())\n\n    dep_delay_minutes = np.clip(dep, 0, None)\n    arr_delay_minutes = np.clip(arr, 0, None)\n\n    # Cancellations and diversions\n    cancelled = (rng.random(n_rows) < 0.015).astype(int)\n    diverted = ((rng.random(n_rows) < 0.003) & (cancelled == 0)).astype(int)\n\n    # Delay flags (15+)\n    dep_del15 = (dep_delay_minutes >= 15).astype(int)\n    arr_del15 = (arr_delay_minutes >= 15).astype(int)\n\n    # Delay causes (simple allocation for demo)\n    total = arr_delay_minutes.copy()\n    # Normalize weights per row\n    w = rng.dirichlet([2, 1.2, 1.4, 0.2, 1.0], size=n_rows)\n    carrier = (total * w[:, 0]).round(0)\n    weather = (total * w[:, 1]).round(0)\n    nas = (total * w[:, 2]).round(0)\n    security = (total * w[:, 3]).round(0)\n    late = (total * w[:, 4]).round(0)\n\n    # When not delayed, causes are zero\n    not_delayed = total < 1\n    carrier[not_delayed] = 0\n    weather[not_delayed] = 0\n    nas[not_delayed] = 0\n    security[not_delayed] = 0\n    late[not_delayed] = 0\n\n    dt = pd.to_datetime(flight_dates)\n\n    df = pd.DataFrame({\n        'FlightDate': dt.strftime('%Y-%m-%d'),\n        'Year': dt.year,\n        'Month': dt.month,\n        'DayOfWeek': (dt.dayofweek + 1),  # BTS uses 1-7\n        'Reporting_Airline': reporting_airline,\n        'Flight_Number_Reporting_Airline': flight_no,\n        'Origin': origin,\n        'Dest': dest,\n        'Distance': distance,\n        'DepDelayMinutes': dep_delay_minutes.round(0),\n        'ArrDelayMinutes': arr_delay_minutes.round(0),\n        'DepDel15': dep_del15,\n        'ArrDel15': arr_del15,\n        'Cancelled': cancelled,\n        'CancellationCode': np.where(cancelled == 1, rng.choice(['A','B','C','D'], size=n_rows), np.nan),\n        'Diverted': diverted,\n        'CarrierDelay': carrier,\n        'WeatherDelay': weather,\n        'NASDelay': nas,\n        'SecurityDelay': security,\n        'LateAircraftDelay': late,\n    })\n\n    # For cancelled flights, delay minutes are not meaningful\n    df.loc[df['Cancelled'] == 1, ['DepDelayMinutes','ArrDelayMinutes','DepDel15','ArrDel15',\n                                 'CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']] = np.nan\n\n    return df\n\n\nif os.path.exists(DATA_PATH):\n    df_raw = read_bts_file(DATA_PATH, usecols=USE_COLS, max_rows=MAX_ROWS_FOR_DEMO)\n    data_origin = f'Loaded from file: {DATA_PATH}'\nelse:\n    df_raw = make_synthetic_bts_like()\n    data_origin = 'Synthetic dataset (file not found)'\n\ndata_origin, df_raw.shape"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319264b5",
   "metadata": {},
   "source": [
    "## 4) Data preparation\n",
    "\n",
    "Key preparation steps:\n",
    "\n",
    "- Parse `FlightDate` into a proper date type.\n",
    "- Create `route` = `Origin`\u2013`Dest`.\n",
    "- Define completion flags (completed vs cancelled/diverted).\n",
    "- Standardize delay metrics and create the core KPI fields.\n",
    "\n",
    "**KPI definitions (common DOT conventions)**\n",
    "\n",
    "- *On\u2011time arrival* (OTP): arrival within **15 minutes** of schedule (based on `ArrDel15`).\n",
    "- *Cancellation rate*: share of flights with `Cancelled = 1`.\n",
    "- *Diversion rate*: share of flights with `Diverted = 1`.\n",
    "\n",
    "Many analyses compute OTP on \u201ccompleted\u201d flights only. This notebook reports both:\n",
    "\n",
    "- OTP on completed flights (excluding cancellations)\n",
    "- \u201cCompletion\u2011adjusted\u201d OTP (treat cancellations as failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95635646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "df['FlightDate'] = pd.to_datetime(df['FlightDate'], errors='coerce')\n",
    "df['route'] = df['Origin'].astype(str) + '-' + df['Dest'].astype(str)\n",
    "\n",
    "# Standardize numeric columns\n",
    "num_cols = ['Distance','DepDelayMinutes','ArrDelayMinutes',\n",
    "            'CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Flags\n",
    "df['is_cancelled'] = (df['Cancelled'] == 1)\n",
    "df['is_diverted'] = (df['Diverted'] == 1)\n",
    "df['is_completed'] = (~df['is_cancelled'])  # diverted flights are still \"not cancelled\" here\n",
    "\n",
    "# OTP flags\n",
    "df['is_arr_ontime'] = (df['ArrDel15'] == 0) & df['is_completed']\n",
    "df['is_arr_delayed15p'] = (df['ArrDel15'] == 1) & df['is_completed']\n",
    "\n",
    "# Time grain helpers\n",
    "df['month'] = df['FlightDate'].dt.to_period('M').dt.to_timestamp()\n",
    "df['week'] = df['FlightDate'].dt.to_period('W').dt.start_time\n",
    "\n",
    "df[['FlightDate','Reporting_Airline','Origin','Dest','ArrDelayMinutes','is_arr_ontime','is_cancelled']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0feb3e8",
   "metadata": {},
   "source": [
    "## 5) KPI monitoring (OTP, delays, cancellations)\n",
    "\n",
    "The KPIs below are computed monthly and can be reused in dashboards:\n",
    "\n",
    "- Flights\n",
    "- OTP (completed flights)\n",
    "- Average arrival delay minutes (completed flights; `ArrDelayMinutes`)\n",
    "- Cancellation rate\n",
    "- Diversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_kpis(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = frame.groupby('month', dropna=False)\n",
    "\n",
    "    flights = g.size()\n",
    "    completed = g['is_completed'].sum(min_count=1)\n",
    "    otp_completed = g['is_arr_ontime'].sum(min_count=1) / completed\n",
    "\n",
    "    avg_arr_delay = g.apply(lambda x: np.nanmean(x.loc[x['is_completed'], 'ArrDelayMinutes']))\n",
    "    cancel_rate = g['is_cancelled'].mean()\n",
    "    divert_rate = g['is_diverted'].mean()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        'flights': flights,\n",
    "        'completed_flights': completed,\n",
    "        'otp_completed': otp_completed,\n",
    "        'avg_arr_delay_min': avg_arr_delay,\n",
    "        'cancel_rate': cancel_rate,\n",
    "        'divert_rate': divert_rate,\n",
    "    }).reset_index()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "kpi_month = monthly_kpis(df)\n",
    "kpi_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(kpi_month['month'], kpi_month['otp_completed'] * 100, marker='o')\n",
    "ax.set_title('On-Time Arrival Performance (OTP) \u2014 Completed Flights')\n",
    "ax.set_ylabel('OTP (%)')\n",
    "ax.set_xlabel('Month')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(kpi_month['month'], kpi_month['avg_arr_delay_min'], marker='o')\n",
    "ax.set_title('Average Arrival Delay Minutes \u2014 Completed Flights')\n",
    "ax.set_ylabel('Minutes')\n",
    "ax.set_xlabel('Month')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(kpi_month['month'], kpi_month['cancel_rate'] * 100, marker='o', label='Cancellation rate')\n",
    "ax.plot(kpi_month['month'], kpi_month['divert_rate'] * 100, marker='o', label='Diversion rate')\n",
    "ax.set_title('Service Disruptions')\n",
    "ax.set_ylabel('Rate (%)')\n",
    "ax.set_xlabel('Month')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c5def",
   "metadata": {},
   "source": [
    "### KPI drill\u2011downs (carrier, airport, route)\n",
    "\n",
    "A small set of drill\u2011downs usually covers the majority of operational questions:\n",
    "\n",
    "- Which carriers have the lowest OTP and highest delay minutes?\n",
    "- Which origin airports show chronic delays?\n",
    "- Which routes have persistent delays (high average delay and high delay frequency)?\n",
    "\n",
    "The tables below include simple eligibility thresholds to reduce small\u2011sample noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a50d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_by(frame: pd.DataFrame, by_col: str, min_flights: int = 500) -> pd.DataFrame:\n",
    "    g = frame.groupby(by_col, dropna=False)\n",
    "    flights = g.size()\n",
    "    completed = g['is_completed'].sum(min_count=1)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        'flights': flights,\n",
    "        'otp_completed': g['is_arr_ontime'].sum(min_count=1) / completed,\n",
    "        'avg_arr_delay_min': g.apply(lambda x: np.nanmean(x.loc[x['is_completed'], 'ArrDelayMinutes'])),\n",
    "        'cancel_rate': g['is_cancelled'].mean(),\n",
    "        'divert_rate': g['is_diverted'].mean(),\n",
    "    })\n",
    "\n",
    "    out = out.loc[out['flights'] >= min_flights].sort_values(['otp_completed', 'avg_arr_delay_min'], ascending=[True, False])\n",
    "    return out\n",
    "\n",
    "\n",
    "by_airline = kpi_by(df, 'Reporting_Airline', min_flights=1000)\n",
    "by_airline.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e704291",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_origin = kpi_by(df, 'Origin', min_flights=1500)\n",
    "by_origin.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_route = kpi_by(df, 'route', min_flights=1500)\n",
    "by_route.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54264645",
   "metadata": {},
   "source": [
    "## 6) Anomaly detection\n",
    "\n",
    "Two operationally useful anomaly patterns:\n",
    "\n",
    "1. **Spikes**: sudden deterioration (e.g., a disrupted day/week) for an airport or route.\n",
    "2. **Chronic underperformance**: sustained low OTP and high delays over many periods.\n",
    "\n",
    "Approach used here:\n",
    "\n",
    "- Aggregate to **weekly** route\u2011level delay minutes.\n",
    "- Compute a rolling baseline (mean and standard deviation) per route.\n",
    "- Flag weeks with a robust z\u2011score above a threshold.\n",
    "\n",
    "The output table highlights the *largest* anomalies and includes context metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly aggregates per route\n",
    "weekly_route = (\n",
    "    df.loc[df['is_completed']]\n",
    "      .groupby(['route','week'], dropna=False)\n",
    "      .agg(\n",
    "          flights=('route','size'),\n",
    "          otp=('is_arr_ontime','mean'),\n",
    "          avg_arr_delay=('ArrDelayMinutes','mean'),\n",
    "          p95_arr_delay=('ArrDelayMinutes', lambda s: np.nanpercentile(s, 95)),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Eligibility threshold\n",
    "weekly_route = weekly_route.loc[weekly_route['flights'] >= 80].copy()\n",
    "\n",
    "# Rolling baseline per route (shifted to avoid leakage)\n",
    "weekly_route = weekly_route.sort_values(['route','week'])\n",
    "weekly_route['roll_mean'] = weekly_route.groupby('route')['avg_arr_delay'].transform(lambda s: s.rolling(8, min_periods=4).mean().shift(1))\n",
    "weekly_route['roll_std']  = weekly_route.groupby('route')['avg_arr_delay'].transform(lambda s: s.rolling(8, min_periods=4).std(ddof=0).shift(1))\n",
    "\n",
    "weekly_route['z_delay'] = (weekly_route['avg_arr_delay'] - weekly_route['roll_mean']) / weekly_route['roll_std']\n",
    "\n",
    "# Robust cleanup\n",
    "weekly_route.loc[weekly_route['roll_std'] == 0, 'z_delay'] = np.nan\n",
    "\n",
    "anomalies = weekly_route.loc[weekly_route['z_delay'] >= 3].sort_values('z_delay', ascending=False)\n",
    "anomalies.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8feed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most extreme anomaly route, if available\n",
    "if len(anomalies) > 0:\n",
    "    sel_route = anomalies.iloc[0]['route']\n",
    "    plot_df = weekly_route.loc[weekly_route['route'] == sel_route].copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(plot_df['week'], plot_df['avg_arr_delay'], marker='o', label='Weekly avg arrival delay')\n",
    "    ax.plot(plot_df['week'], plot_df['roll_mean'], linestyle='--', label='Rolling baseline (8w)')\n",
    "    ax.set_title(f'Weekly Arrival Delay \u2014 Route {sel_route}')\n",
    "    ax.set_ylabel('Minutes')\n",
    "    ax.set_xlabel('Week')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No anomalies detected with the current thresholds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c090c0",
   "metadata": {},
   "source": [
    "### Chronic delay ranking\n",
    "\n",
    "\u201cChronic\u201d routes and airports are identified by combining:\n",
    "\n",
    "- high average arrival delay minutes, and\n",
    "- high frequency of 15+ minute delays.\n",
    "\n",
    "The score below is a simple weighted index and can be replaced by a more formal control chart or statistical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chronic_score(frame: pd.DataFrame, by_col: str, min_flights: int = 5000) -> pd.DataFrame:\n",
    "    g = frame.loc[frame['is_completed']].groupby(by_col, dropna=False)\n",
    "    flights = g.size()\n",
    "\n",
    "    avg_delay = g['ArrDelayMinutes'].mean()\n",
    "    delay_freq = g['is_arr_delayed15p'].mean()\n",
    "\n",
    "    # Score: emphasize frequency while retaining magnitude\n",
    "    score = 0.65 * delay_freq + 0.35 * (avg_delay / (avg_delay.median() + 1e-9))\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        'flights': flights,\n",
    "        'avg_arr_delay_min': avg_delay,\n",
    "        'delay_15p_rate': delay_freq,\n",
    "        'chronic_score': score\n",
    "    })\n",
    "\n",
    "    out = out.loc[out['flights'] >= min_flights].sort_values('chronic_score', ascending=False)\n",
    "    return out\n",
    "\n",
    "\n",
    "chronic_routes = chronic_score(df, 'route', min_flights=6000)\n",
    "chronic_routes.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "chronic_airports = chronic_score(df, 'Origin', min_flights=8000)\n",
    "chronic_airports.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b468af",
   "metadata": {},
   "source": [
    "## 7) Root\u2011cause by delay type\n",
    "\n",
    "BTS includes delay minutes by cause for many (but not necessarily all) flights/periods:\n",
    "\n",
    "- `CarrierDelay`\n",
    "- `WeatherDelay`\n",
    "- `NASDelay`\n",
    "- `SecurityDelay`\n",
    "- `LateAircraftDelay`\n",
    "\n",
    "Root\u2011cause analytics is typically framed as:\n",
    "\n",
    "- distribution of delay minutes by cause over time,\n",
    "- top causes at specific airports or for specific carriers.\n",
    "\n",
    "**Interpretation note**\n",
    "\n",
    "Cause fields are typically populated for delayed flights and may have missing values for other records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_cols = ['CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "\n",
    "cause_month = (\n",
    "    df.loc[df['is_completed']]\n",
    "      .groupby('month')[cause_cols]\n",
    "      .sum(min_count=1)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "cause_month['total_cause_delay'] = cause_month[cause_cols].sum(axis=1)\n",
    "\n",
    "for c in cause_cols:\n",
    "    cause_month[c + '_share'] = cause_month[c] / cause_month['total_cause_delay']\n",
    "\n",
    "cause_month[['month'] + [c + '_share' for c in cause_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58783c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart of delay cause shares\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "x = cause_month['month']\n",
    "y = [cause_month[c + '_share'].fillna(0).values for c in cause_cols]\n",
    "ax.stackplot(x, y, labels=cause_cols)\n",
    "ax.set_title('Delay Cause Shares Over Time (Share of Minutes)')\n",
    "ax.set_ylabel('Share')\n",
    "ax.set_xlabel('Month')\n",
    "ax.legend(loc='upper right', ncol=2)\n",
    "ax.grid(True, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top causes by origin airport (minutes)\n",
    "airport_cause = (\n",
    "    df.loc[df['is_completed']]\n",
    "      .groupby('Origin')[cause_cols]\n",
    "      .sum(min_count=1)\n",
    "      .sort_values(cause_cols, ascending=False)\n",
    ")\n",
    "\n",
    "airport_cause.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66105a",
   "metadata": {},
   "source": [
    "## 8) Forecasting: short\u2011horizon delay outlook\n",
    "\n",
    "A lightweight forecasting example uses weekly average arrival delay minutes and Holt\u2011Winters exponential smoothing.\n",
    "\n",
    "The purpose is operational planning (risk outlook), not a long\u2011range demand forecast.\n",
    "\n",
    "- Train/test split: last 20% of weeks held out\n",
    "- Output: next 8 weeks forecast and backtest performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = (\n",
    "    df.loc[df['is_completed']]\n",
    "      .groupby('week')['ArrDelayMinutes']\n",
    "      .mean()\n",
    "      .dropna()\n",
    "      .asfreq('W-MON')\n",
    ")\n",
    "\n",
    "# Fill gaps (rare in full extracts; possible in synthetic)\n",
    "ts = ts.interpolate(limit_direction='both')\n",
    "\n",
    "split_idx = int(len(ts) * 0.8)\n",
    "ts_train, ts_test = ts.iloc[:split_idx], ts.iloc[split_idx:]\n",
    "\n",
    "# Additive trend, no seasonality by default (weekly data may show yearly seasonality in larger history)\n",
    "model = ExponentialSmoothing(ts_train, trend='add', seasonal=None, initialization_method='estimated')\n",
    "fit = model.fit(optimized=True)\n",
    "\n",
    "# Backtest on test horizon\n",
    "pred_test = fit.forecast(len(ts_test))\n",
    "\n",
    "# Simple error metrics\n",
    "mae = float(np.mean(np.abs(ts_test.values - pred_test.values)))\n",
    "\n",
    "# Forecast next 8 weeks\n",
    "forecast_h = 8\n",
    "pred_future = fit.forecast(len(ts_test) + forecast_h).iloc[-forecast_h:]\n",
    "\n",
    "mae, pred_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94728ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(ts_train.index, ts_train.values, label='Train')\n",
    "ax.plot(ts_test.index, ts_test.values, label='Test')\n",
    "ax.plot(ts_test.index, pred_test.values, linestyle='--', label='Predicted (test)')\n",
    "ax.set_title(f'Weekly Avg Arrival Delay \u2014 Backtest (MAE = {mae:.2f} minutes)')\n",
    "ax.set_ylabel('Minutes')\n",
    "ax.set_xlabel('Week')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3.6))\n",
    "ax.plot(ts.index, ts.values, label='History')\n",
    "ax.plot(pred_future.index, pred_future.values, linestyle='--', label='Forecast (next 8 weeks)')\n",
    "ax.set_title('Weekly Avg Arrival Delay \u2014 Short-Horizon Forecast')\n",
    "ax.set_ylabel('Minutes')\n",
    "ax.set_xlabel('Week')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425f9a2",
   "metadata": {},
   "source": [
    "## 9) Delay risk model: probability of 15+ minute arrival delay\n",
    "\n",
    "A simple baseline classifier estimates the probability that a completed flight arrives 15+ minutes late.\n",
    "\n",
    "**Target**\n",
    "\n",
    "- `delayed15p` = 1 if `ArrDel15 == 1` and flight is completed\n",
    "\n",
    "**Candidate features** (examples)\n",
    "\n",
    "- carrier, origin, destination\n",
    "- day of week, month\n",
    "- distance\n",
    "\n",
    "**Validation**\n",
    "\n",
    "- Time\u2011based split (train on earlier dates, test on later dates)\n",
    "- Metrics: ROC\u2011AUC and average precision\n",
    "\n",
    "This is deliberately conservative: no leakage features (e.g., actual departure delay) are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.loc[df['is_completed']].copy()\n",
    "\n",
    "# Target\n",
    "model_df['delayed15p'] = (model_df['ArrDel15'] == 1).astype(int)\n",
    "\n",
    "# Feature set\n",
    "features_cat = ['Reporting_Airline','Origin','Dest','DayOfWeek','Month']\n",
    "features_num = ['Distance']\n",
    "\n",
    "model_df = model_df.dropna(subset=['FlightDate','delayed15p'])\n",
    "\n",
    "# Sort by time and split\n",
    "model_df = model_df.sort_values('FlightDate')\n",
    "split_idx = int(len(model_df) * 0.8)\n",
    "\n",
    "train_df = model_df.iloc[:split_idx]\n",
    "test_df = model_df.iloc[split_idx:]\n",
    "\n",
    "X_train = train_df[features_cat + features_num]\n",
    "y_train = train_df['delayed15p']\n",
    "X_test = test_df[features_cat + features_num]\n",
    "y_test = test_df['delayed15p']\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), features_cat),\n",
    "        ('num', StandardScaler(), features_num),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=200, n_jobs=None)\n",
    "\n",
    "pipe = Pipeline(steps=[('pre', pre), ('clf', clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "ap = average_precision_score(y_test, proba)\n",
    "\n",
    "roc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce070bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, proba)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--')\n",
    "ax.set_title(f'ROC Curve (AUC = {roc:.3f})')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example operating point: threshold that flags roughly ~15% highest-risk flights\n",
    "threshold = float(np.quantile(proba, 0.85))\n",
    "pred = (proba >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "report = classification_report(y_test, pred, digits=3)\n",
    "\n",
    "cm, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67897219",
   "metadata": {},
   "source": [
    "## 10) Summary and operational mapping\n",
    "\n",
    "This notebook demonstrates an end\u2011to\u2011end workflow on BTS OTP data:\n",
    "\n",
    "- KPI monitoring for OTP, delays, and service disruptions\n",
    "- anomaly detection for spikes and chronic underperformance\n",
    "- delay cause decomposition for root\u2011cause framing\n",
    "- short\u2011horizon forecasting for proactive planning\n",
    "- baseline delay\u2011risk scoring for operational triage\n",
    "\n",
    "Possible extensions (typical in production environments):\n",
    "\n",
    "- incorporate scheduled time blocks (`CRSDepTime`, `CRSArrTime`) and bank structure\n",
    "- include aircraft tail number and aircraft type (where available)\n",
    "- add weather data joins at station/airport level\n",
    "- build a dashboard layer (e.g., Power BI / Tableau / Streamlit)\n",
    "- use hierarchical models per airport/network for better generalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}